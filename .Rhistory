load("/Volumes/DATA/Github/DataDrivenTrading/etf_data.rda")
df
head(df)
rm(df)
load("/Volumes/DATA/Github/DataDrivenTrading/etfdb_data.rda")
df
head(df)
f <- data.frame(read_excel("etfdb_data.xls"))
colnames(df) = c("symbol","name","etfdb.category","inception.date","expense.ratio","commission.free","expenses.rating")
# Correct Excel format date for inception date
df$inception.date = as.Date(df$inception.date,origin = "1899-12-30")
df["c.issuer"] = gsub( " .*$", "", df$name )
n.top = 10
df.ac = psel(subset(df,etfdb.category == "All Cap Equities"),low(expense.ratio),top = n.top)
df.lcb = psel(subset(df,etfdb.category == "Large Cap Blend Equities"),low(expense.ratio),top = n.top)
df.lcg = psel(subset(df,etfdb.category == "Large Cap Growth Equities"),low(expense.ratio),top = n.top)
df.lcv = psel(subset(df,etfdb.category == "Large Cap Value Equities"),low(expense.ratio),top = n.top)
df.mcb = psel(subset(df,etfdb.category == "Mid Cap Blend Equities"),low(expense.ratio),top = n.top)
df.mcg = psel(subset(df,etfdb.category == "Mid Cap Growth Equities"),low(expense.ratio),top = n.top)
df.mcv = psel(subset(df,etfdb.category == "Mid Cap Value Equities"),low(expense.ratio),top = n.top)
df.scb = psel(subset(df,etfdb.category == "Small Cap Blend Equities"),low(expense.ratio),top = n.top)
df.scg = psel(subset(df,etfdb.category == "Small Cap Growth Equities"),low(expense.ratio),top = n.top)
df.scv = psel(subset(df,etfdb.category == "Small Cap Value Equities"),low(expense.ratio),top = n.top)
library(readxl)
library(rPref)
f <- data.frame(read_excel("etfdb_data.xls"))
colnames(df) = c("symbol","name","etfdb.category","inception.date","expense.ratio","commission.free","expenses.rating")
# Correct Excel format date for inception date
df$inception.date = as.Date(df$inception.date,origin = "1899-12-30")
df["c.issuer"] = gsub( " .*$", "", df$name )
n.top = 10
df.ac = psel(subset(df,etfdb.category == "All Cap Equities"),low(expense.ratio),top = n.top)
df.lcb = psel(subset(df,etfdb.category == "Large Cap Blend Equities"),low(expense.ratio),top = n.top)
df.lcg = psel(subset(df,etfdb.category == "Large Cap Growth Equities"),low(expense.ratio),top = n.top)
df.lcv = psel(subset(df,etfdb.category == "Large Cap Value Equities"),low(expense.ratio),top = n.top)
df.mcb = psel(subset(df,etfdb.category == "Mid Cap Blend Equities"),low(expense.ratio),top = n.top)
df.mcg = psel(subset(df,etfdb.category == "Mid Cap Growth Equities"),low(expense.ratio),top = n.top)
df.mcv = psel(subset(df,etfdb.category == "Mid Cap Value Equities"),low(expense.ratio),top = n.top)
df.scb = psel(subset(df,etfdb.category == "Small Cap Blend Equities"),low(expense.ratio),top = n.top)
df.scg = psel(subset(df,etfdb.category == "Small Cap Growth Equities"),low(expense.ratio),top = n.top)
df.scv = psel(subset(df,etfdb.category == "Small Cap Value Equities"),low(expense.ratio),top = n.top)
load("/Volumes/DATA/Github/DataDrivenTrading/2016-10-01 20161001_etfdb_allsites.rda")
all.sites
df
head(df)
table(c.issuer)
table(df$c.issuer)
head(df)
all.stocks.list = vector("list",nrow(df.target))
for (i in 1:nrow(df.target)){
data = read.csv(paste(data_path,df.target$symbol[i],".csv",sep = ""),header = TRUE,sep = ",",stringsAsFactors = FALSE)
all.stocks.list[[i]] = xts(x = data,order.by = as.Date(data$Index))
}
rm(list=ls())
library(readxl)
library(quantmod)
library(R.utils) # for countlines
directory = "/Volumes/DATA/Github/LazyPortfolioAnalytics"
data_path = "/Volumes/DATA/Dropbox/Data/LazyPortfolioAnalytics/OHLC"
setwd(directory)
# Reads in last update information
#df.log = read.table("log.csv",header = TRUE,sep = ",", stringsAsFactors=F)
# Load list of target instruments
df.source <- data.frame(read_excel("etfdb_data.xls"))
# Delete all irrelevant columns
df.target = within(df.source,rm(name,etfdb.category,inception.date,expense.ratio,commission.free,expenses.rating))
# Create another column to keep track of its existence in folder
df.target["exists"] = rep(NA,nrow(df.target))
# Check folder to determine which instruments have been scraped
existing.files = list.files("./Data/OHLC",full.names = FALSE) # fetch list of all files from folder
existing.files = gsub(".csv","",existing.files) # remove ".csv" from vector of characters
# Perform comparisons to determine if target instrument exists and if it is updated
for (i in 1:nrow(df.target)){
df.target$exists[i] = df.target$symbol[i] %in% existing.files
}
all.stocks.list = vector("list",nrow(df.target))
for (i in 1:nrow(df.target)){
data = read.csv(paste(data_path,df.target$symbol[i],".csv",sep = ""),header = TRUE,sep = ",",stringsAsFactors = FALSE)
all.stocks.list[[i]] = xts(x = data,order.by = as.Date(data$Index))
}
rm(list=ls())
library(readxl)
library(quantmod)
library(R.utils) # for countlines
directory = "/Volumes/DATA/Github/LazyPortfolioAnalytics"
data_path = "/Volumes/DATA/Dropbox/Data/LazyPortfolioAnalytics/OHLC/"
setwd(directory)
# Reads in last update information
#df.log = read.table("log.csv",header = TRUE,sep = ",", stringsAsFactors=F)
# Load list of target instruments
df.source <- data.frame(read_excel("etfdb_data.xls"))
# Delete all irrelevant columns
df.target = within(df.source,rm(name,etfdb.category,inception.date,expense.ratio,commission.free,expenses.rating))
# Create another column to keep track of its existence in folder
df.target["exists"] = rep(NA,nrow(df.target))
# Check folder to determine which instruments have been scraped
existing.files = list.files("./Data/OHLC",full.names = FALSE) # fetch list of all files from folder
existing.files = gsub(".csv","",existing.files) # remove ".csv" from vector of characters
# Perform comparisons to determine if target instrument exists and if it is updated
for (i in 1:nrow(df.target)){
df.target$exists[i] = df.target$symbol[i] %in% existing.files
}
# Recreate log
df.log = data.frame("fetched.symbol" = "",
"fetched.date" = "",
"fetched.status" = "",
stringsAsFactors=FALSE)
all.stocks.list = vector("list",nrow(df.target))
for (i in 1:nrow(df.target)){
data = read.csv(paste(data_path,df.target$symbol[i],".csv",sep = ""),header = TRUE,sep = ",",stringsAsFactors = FALSE)
all.stocks.list[[i]] = xts(x = data,order.by = as.Date(data$Index))
}
source('/Volumes/DATA/Github/DataDrivenTrading/OHLC_scraper.R')
df.log
df.log
tryCatch({
for (i in 1:nrow(df.target)){
data = read.csv(paste(data_path,df.target$symbol[i],".csv",sep = ""),header = TRUE,sep = ",",stringsAsFactors = FALSE)
all.stocks.list[[i]] = xts(x = data,order.by = as.Date(data$Index))
}
})
# Save all target stocks as merged XTS
all.stocks.list = vector("list",nrow(df.target))
tryCatch({
for (i in 1:nrow(df.target)){
data = read.csv(paste(data_path,df.target$symbol[i],".csv",sep = ""),header = TRUE,sep = ",",stringsAsFactors = FALSE)
all.stocks.list[[i]] = xts(x = data,order.by = as.Date(data$Index))
}
})
for (i in 1:nrow(df.target)){
tryCatch({
data = read.csv(paste(data_path,df.target$symbol[i],".csv",sep = ""),header = TRUE,sep = ",",stringsAsFactors = FALSE)
all.stocks.list[[i]] = xts(x = data,order.by = as.Date(data$Index))
})
}
for (i in 1:nrow(df.target)){
data = try(read.csv(paste(data_path,df.target$symbol[i],".csv",sep = ""),header = TRUE,sep = ",",stringsAsFactors = FALSE))
all.stocks.list[[i]] = try(xts(x = data,order.by = as.Date(data$Index)))
}
all.stocks.list[[9]]
all.stocks.list[[100]]
all.stocks.list[[356]]
for (i in 1:nrow(df.target)){
data = try(read.csv(paste(data_path,df.target$symbol[i],".csv",sep = ""),header = TRUE,sep = ",",stringsAsFactors = FALSE))
all.stocks.list[[i]] = try(xts(x = data,order.by = as.Date(data$Index)))
}
df.log
grepl("RORO",df.target)
grepl("RORO",df.target$symbol)
grep("RORO",df.target$symbol)
all.stocks.list[[53]]
class(all.stocks.list[[53]])
class(all.stocks.list[[52]])
