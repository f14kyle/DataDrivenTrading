tickersZoo = paste(tickersZoo,bench.tickers[i],"[,6],",sep = "")
}
tickersZoo = paste(tickersZoo,")",sep = "")
tickersZoo = substr(tickersZoo,1,nchar(tickersZoo)-2)
tickersZoo = paste(tickersZoo,")",sep = "")
allStocks = merge(GSPC[,6],RUT[,6],MSCI[,6],AGG[,6])
x.R =  na.omit(Return.calculate(allStocks["2006-03/2016-03"]))
for (i in 1:nrow(c)){
bench.returns = Return.portfolio(x.R,weights = as.numeric(c[i,]),geometric = TRUE,rebalance_on = "years")
bench.all[i,1] = Return.annualized(bench.returns, scale = NA, geometric = TRUE)
bench.all[i,1] = as.numeric(c[i,]) %*% bench.returns
bench.all[i,2] = DownsideDeviation(bench.returns, MAR = 0,method = "subset")
bench.all[i,3] = maxDrawdown(bench.returns, geometric = TRUE, invert = TRUE)
}
df.bench.all = cbind(c,bench.all)
colnames(df.bench.all) = c("GSPC","RUT","CWI","AGG","CAGR","DD","MD")
# Load benchmarks
bench.tickers = c("^GSPC","^RUT","MSCI","AGG")
bench.names = c("S&P 500,Russell 2000","MSCI ACWI IMI Ex-US","Barclays U.S. Aggregate Bond")
tickers.count = length(bench.tickers)
for (i in 1:tickers.count){
try(getSymbols(bench.tickers[i], src = "yahoo"))
}
tickersZoo = "merge("
for (i in 1:tickers.count){
tickersZoo = paste(tickersZoo,bench.tickers[i],"[,6],",sep = "")
}
tickersZoo = paste(tickersZoo,")",sep = "")
tickersZoo = substr(tickersZoo,1,nchar(tickersZoo)-2)
tickersZoo = paste(tickersZoo,")",sep = "")
allStocks = merge(GSPC[,6],RUT[,6],MSCI[,6],AGG[,6])
x.R =  na.omit(Return.calculate(allStocks["2006-03/2016-03"]))
df.bench.all = cbind(c,bench.all)
for (i in 1:nrow(c)){
bench.returns = Return.portfolio(x.R,weights = as.numeric(c[i,]),geometric = TRUE,rebalance_on = "years")
bench.all[i,1] = Return.annualized(bench.returns, scale = NA, geometric = TRUE)
bench.all[i,1] = as.numeric(c[i,]) %*% bench.returns
bench.all[i,2] = DownsideDeviation(bench.returns, MAR = 0,method = "subset")
bench.all[i,3] = maxDrawdown(bench.returns, geometric = TRUE, invert = TRUE)
}
df.bench.all = cbind(c,bench.all)
colnames(df.bench.all) = c("GSPC","RUT","CWI","AGG","CAGR","DD","MD")
# Load benchmarks
bench.tickers = c("^GSPC","^RUT","MSCI","AGG")
bench.names = c("S&P 500,Russell 2000","MSCI ACWI IMI Ex-US","Barclays U.S. Aggregate Bond")
tickers.count = length(bench.tickers)
for (i in 1:tickers.count){
try(getSymbols(bench.tickers[i], src = "yahoo"))
}
tickersZoo = "merge("
for (i in 1:tickers.count){
tickersZoo = paste(tickersZoo,bench.tickers[i],"[,6],",sep = "")
}
tickersZoo = paste(tickersZoo,")",sep = "")
tickersZoo = substr(tickersZoo,1,nchar(tickersZoo)-2)
tickersZoo = paste(tickersZoo,")",sep = "")
allStocks = merge(GSPC[,6],RUT[,6],MSCI[,6],AGG[,6])
x.R =  na.omit(Return.calculate(allStocks["2006-03/2016-03"]))
bench.all = matrix(0,nrow = nrow(c),ncol = 3)
for (i in 1:nrow(c)){
bench.returns = Return.portfolio(x.R,weights = as.numeric(c[i,]),geometric = TRUE,rebalance_on = "years")
bench.all[i,1] = Return.annualized(bench.returns, scale = NA, geometric = TRUE)
bench.all[i,1] = as.numeric(c[i,]) %*% bench.returns
bench.all[i,2] = DownsideDeviation(bench.returns, MAR = 0,method = "subset")
bench.all[i,3] = maxDrawdown(bench.returns, geometric = TRUE, invert = TRUE)
}
df.bench.all = cbind(c,bench.all)
colnames(df.bench.all) = c("GSPC","RUT","CWI","AGG","CAGR","DD","MD")
plot.bench = ggplot() +
geom_point(data = df.bench.all,aes(x = MD,y = CAGR),colour = "gray")
plot.bench
df.bench.all
# Load benchmarks
bench.tickers = c("^GSPC","^RUT","MSCI","AGG")
bench.names = c("S&P 500,Russell 2000","MSCI ACWI IMI Ex-US","Barclays U.S. Aggregate Bond")
tickers.count = length(bench.tickers)
for (i in 1:tickers.count){
try(getSymbols(bench.tickers[i], src = "yahoo"))
}
tickersZoo = "merge("
for (i in 1:tickers.count){
tickersZoo = paste(tickersZoo,bench.tickers[i],"[,6],",sep = "")
}
tickersZoo = paste(tickersZoo,")",sep = "")
tickersZoo = substr(tickersZoo,1,nchar(tickersZoo)-2)
tickersZoo = paste(tickersZoo,")",sep = "")
allStocks = merge(GSPC[,6],RUT[,6],MSCI[,6],AGG[,6])
x.R =  na.omit(Return.calculate(allStocks["2006-03/2016-03"]))
bench.all = matrix(0,nrow = nrow(c),ncol = 3)
for (i in 1:nrow(c)){
bench.returns = Return.portfolio(x.R,weights = as.numeric(c[i,]),geometric = TRUE,rebalance_on = "years")
bench.all[i,1] = Return.annualized(bench.returns, scale = NA, geometric = TRUE)
bench.all[i,1] = as.numeric(c[i,]) %*% bench.returns
bench.all[i,2] = DownsideDeviation(bench.returns, MAR = 0,method = "subset")
bench.all[i,3] = maxDrawdown(bench.returns, geometric = TRUE, invert = TRUE)
}
df.bench.all = cbind(c,bench.all)
colnames(df.bench.all) = c("GSPC","RUT","CWI","AGG","CAGR","DD","MD")
plot.bench = ggplot() +
geom_point(data = df.bench.all,aes(x = MD,y = CAGR),colour = "gray")
plot.bench
plot.bench
bench.all
GSPC
c
for (i in 1:nrow(c)){
bench.returns = Return.portfolio(x.R,weights = as.numeric(c[i,]),geometric = TRUE,rebalance_on = "years")
bench.all[i,1] = Return.annualized(bench.returns, scale = NA, geometric = TRUE)
bench.all[i,1] = as.numeric(c[i,]) %*% bench.returns
bench.all[i,2] = DownsideDeviation(bench.returns, MAR = 0,method = "subset")
bench.all[i,3] = maxDrawdown(bench.returns, geometric = TRUE, invert = TRUE)
}
x.R
bench.returns
for (i in 1:nrow(c)){
bench.returns = Return.portfolio(x.R,weights = as.numeric(c[i,]),geometric = TRUE,rebalance_on = "years")
bench.all[i,1] = Return.annualized(bench.returns, scale = NA, geometric = TRUE)
bench.all[i,2] = DownsideDeviation(bench.returns, MAR = 0,method = "subset")
bench.all[i,3] = maxDrawdown(bench.returns, geometric = TRUE, invert = TRUE)
}
df.bench.all = cbind(c,bench.all)
colnames(df.bench.all) = c("GSPC","RUT","CWI","AGG","CAGR","DD","MD")
plot.bench = ggplot() +
geom_point(data = df.bench.all,aes(x = MD,y = CAGR),colour = "gray")
plot.bench
plot.bench
df.pareto.bench = psel(df.index.all,high(CAGR) * low(MD))
df.pareto.bench
df.pareto.bench = psel(df.index.all,high(CAGR) * low(DD))
df.pareto.bench = psel(df.bench.all,high(CAGR) * low(DD))
df.pareto.bench
df.pareto.bench = psel(df.bench.all,high(CAGR) * low(MD))
df.pareto.bench
plot.bench = ggplot() +
geom_point(data = df.bench.all,aes(x = MD,y = CAGR),colour = "gray") +
geom_point(data = df.bench.all,aes(x = MD,y = MD),colour = "red") +
geom_point(data = df.bench.all,aes(x = MD,y = DD),colour = "orange") +
plot.bench
plot.bench = ggplot() +
geom_point(data = df.bench.all,aes(x = MD,y = CAGR),colour = "gray") +
geom_point(data = df.pareto.bench.DD,aes(x = MD,y = MD),colour = "red") +
geom_point(data = df.pareto.bench.MD,aes(x = MD,y = DD),colour = "orange")
plot.bench
df.pareto.bench.DD = psel(df.bench.all,high(CAGR) * low(DD))
df.pareto.bench.MD = psel(df.bench.all,high(CAGR) * low(MD))
plot.bench = ggplot() +
geom_point(data = df.bench.all,aes(x = MD,y = CAGR),colour = "gray") +
geom_point(data = df.pareto.bench.DD,aes(x = MD,y = MD),colour = "red") +
geom_point(data = df.pareto.bench.MD,aes(x = MD,y = DD),colour = "orange")
plot.bench
plot.bench
plot.bench = ggplot() +
geom_point(data = df.bench.all,aes(x = MD,y = CAGR),colour = "gray") +
geom_point(data = df.pareto.bench.MD,aes(x = MD,y = DD),colour = "orange")
plot.bench
plot.bench = ggplot() +
geom_point(data = df.bench.all,aes(x = MD,y = CAGR),colour = "gray") +
geom_point(data = df.pareto.bench.MD,aes(x = MD,y = CAGR),colour = "orange")
plot.bench
plot.bench
plot.bench = ggplot() +
geom_point(data = df.bench.all,aes(x = DD,y = CAGR),colour = "gray") +
geom_point(data = df.pareto.bench.DD,aes(x = DD,y = CAGR),colour = "orange")
plot.bench
plot.bench
df.pareto.bench.DD
df.pareto.bench.DD[,1:4]
df.pareto.bench.DD[,1:4] == df.pareto.bench.MD[,1:4]
nrow(df.pareto.bench.DD[,1:4])
nrow(df.pareto.bench.MD[,1:4])
nrow(df.pareto.bench.DD[,1:4])
df.pareto.bench.DD[,1:4]
df.pareto.bench.MD[,1:4]
plot.index
load("D:/Dropbox/Github/retirement-planner/df_lazy.rda")
df.lazy
plot.dd
plot.dd
df.lazy
plot.dd = ggplot() +
geom_point(data = df.lazy,aes(x = DD,y = CAGR,colour = Names),size = 2) +
scale_colour_brewer(palette = "Spectral") +
theme_dark() +
scale_y_continuous(labels = percent) +
scale_x_continuous(labels = percent) +
labs(title = "Annualized Returns vs Downside Deviation",
x = "Maximum Drawdown",
y = "Annualized Returns") +
facet_grid(. ~ Period) +
theme(legend.title=element_blank(),legend.position = "bottom")
library(ggplot2)
plot.dd = ggplot() +
geom_point(data = df.lazy,aes(x = DD,y = CAGR,colour = Names),size = 2) +
scale_colour_brewer(palette = "Spectral") +
theme_dark() +
scale_y_continuous(labels = percent) +
scale_x_continuous(labels = percent) +
labs(title = "Annualized Returns vs Downside Deviation",
x = "Maximum Drawdown",
y = "Annualized Returns") +
facet_grid(. ~ Period) +
theme(legend.title=element_blank(),legend.position = "bottom")
library(scales)
plot.dd = ggplot() +
geom_point(data = df.lazy,aes(x = DD,y = CAGR,colour = Names),size = 2) +
scale_colour_brewer(palette = "Spectral") +
theme_dark() +
scale_y_continuous(labels = percent) +
scale_x_continuous(labels = percent) +
labs(title = "Annualized Returns vs Downside Deviation",
x = "Maximum Drawdown",
y = "Annualized Returns") +
facet_grid(. ~ Period) +
theme(legend.title=element_blank(),legend.position = "bottom")
plot.dd
scat.cagr.vs.md
plot.rebal1 = ggplot() +
geom_point(data = subset(df.lazy,Timeframe == "1 year"),aes(x = as.character(Name),y = as.numeric(CAGR),colour = Rebalance.Period),size = 2) +
scale_y_continuous(labels = percent) +
labs(title = "Sensitivity of CAGR to Rebalance Period for 1 Year Timeframe",
x = "Lazy Portfolios",
y = "Annualized Returns") +
theme(legend.title=element_blank(),
legend.position = "top",
axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.3))
plot.rebal3 = ggplot() +
geom_point(data = subset(df.lazy,Timeframe == "3 years"),aes(x = as.character(Name),y = as.numeric(CAGR),colour = Rebalance.Period),size = 2) +
scale_y_continuous(labels = percent) +
labs(title = "Sensitivity of CAGR to Rebalance Period for 3 Year Timeframe",
x = "Lazy Portfolios",
y = "Annualized Returns") +
theme(legend.title=element_blank(),
legend.position = "top",
axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.3))
plot.rebal5 = ggplot() +
geom_point(data = subset(df.lazy,Timeframe == "5 years"),aes(x = as.character(Name),y = as.numeric(CAGR),colour = Rebalance.Period),size = 2) +
scale_y_continuous(labels = percent) +
labs(title = "Sensitivity of CAGR to Rebalance Period for 5 Year Timeframe",
x = "Lazy Portfolios",
y = "Annualized Returns") +
theme(legend.title=element_blank(),
legend.position = "top",
axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.3))
plot.rebal7 = ggplot() +
geom_point(data = subset(df.lazy,Timeframe == "7 years"),aes(x = as.character(Name),y = as.numeric(CAGR),colour = Rebalance.Period),size = 2) +
scale_y_continuous(labels = percent) +
labs(title = "Sensitivity of CAGR to Rebalance Period for 7 Year Timeframe",
x = "Lazy Portfolios",
y = "Annualized Returns") +
theme(legend.title=element_blank(),
legend.position = "top",
axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.3))
scat.cagr.vs.dd = ggplot() +
geom_point(data = df.lazy,aes(x = as.numeric(levels(DD))[DD],y = as.numeric(CAGR),colour = Name)) +
scale_colour_manual(values = palette(rainbow(18))) +
theme_dark() +
scale_y_continuous(labels = percent) +
scale_x_continuous(labels = percent) +
labs(title = "Annualized Returns vs. Downside Deviation",
x = "Downside Deviation",
y = "Annualized Returns") +
facet_grid(Timeframe ~ Rebalance.Period,scales = "free") +
theme(legend.title=element_blank(),legend.position = "bottom")
scat.cagr.vs.md = ggplot() +
geom_point(data = df.lazy,aes(x = as.numeric(levels(MD))[MD],y = as.numeric(CAGR),colour = Name),size = 2) +
scale_colour_brewer(palette = "Spectral") +
theme_dark() +
scale_y_continuous(labels = percent) +
scale_x_continuous(labels = percent,trans = "reverse") +
labs(title = "Annualized Returns vs. Maximum Drawdown",
x = "Maximum Drawdown",
y = "Annualized Returns") +
facet_grid(Timeframe ~ Rebalance.Period) +
theme(legend.title=element_blank(),legend.position = "bottom")
scat.cagr.vs.md
scat.cagr.vs.dd
df.lazy
scat.cagr.vs.dd = ggplot() +
geom_point(data = df.lazy,aes(x = as.numeric(levels(DD))[DD],y = as.numeric(CAGR),colour = Name)) +
scale_colour_manual(values = palette(rainbow(18))) +
theme_dark() +
scale_y_continuous(labels = percent) +
scale_x_continuous(labels = percent) +
labs(title = "Annualized Returns vs. Downside Deviation",
x = "Downside Deviation",
y = "Annualized Returns") +
facet_grid(Timeframe ~ Rebalance.Period,scales = "free") +
theme(legend.title=element_blank(),legend.position = "bottom")
scat.cagr.vs.dd
scat.cagr.vs.md
source('D:/Dropbox/Github/retirement-planner/401k_analysis.R')
plot
source('D:/Dropbox/Github/boeing_401k/analysis.R')
# Overlay the market
# Overlay the funds
# Overlay the minimum constraints on funds
# Overlay the optimization
# Overlay Lifecycle 2050
# Overlay Balanced Index
library(quantmod)
library(PerformanceAnalytics)
library(ggplot2)
library(rPref)
tickers.bench = c("VTI","TLT","BIL","GOLD")
names.bench = c("Total Stocks","20+ Year Treasury","1-3 Month T-Bill","Swiss Gold")
tickers.count = length(tickers.bench)
for (i in 1:tickers.count){
try(getSymbols(tickers.bench[i], src = "yahoo"))
}
tickersZoo = "merge("
for (i in 1:tickers.count){
tickersZoo = paste(tickersZoo,tickers.bench[i],"[,6],",sep = "")
}
tickersZoo = paste(tickersZoo,")",sep = "")
tickersZoo = substr(tickersZoo,1,nchar(tickersZoo)-2)
tickersZoo = paste(tickersZoo,")",sep = "")
#allStocks = merge(GSPC[,6],RUT[,6],MSCI[,6],AGG[,6])
allStocks = merge(VTI[,6],TLT[,6],BIL[,6],GOLD[,6])
x.R =  na.omit(Return.calculate(allStocks["2006-01/2016-08"]))
a = seq(from = 0.1, to = 1,by = .05)
b = expand.grid(a,a,a,a)
c = b[rowSums(b) == 1,]
returns = as.xts(matrix(0,nrow = nrow(x.R), ncol = 4),order.by = index(x.R))
metrics.minor = matrix(0,nrow = nrow(c),ncol = 2)
for (i in 1:nrow(c)){
returns = Return.portfolio(x.R,weights = as.numeric(c[i,]),geometric = TRUE,rebalance_on = "years")
metrics.minor[i,1] = Return.annualized(returns, scale = NA, geometric = TRUE)
metrics.minor[i,2] = DownsideDeviation(returns, MAR = 0,method = "subset")
}
metrics.minor
df.results.minor = cbind(c,metrics.minor)
colnames(df.results.minor) = c("VTI","TLT","BIL","GOLD","CAGR","DD")
c
nrow(c)
metrics.minor
df.results.minor
head(df.results.minor)
pareto.minor = psel(df.results.minor, high(CAGR) * low(DD))
pareto.minor
plot = ggplot() +
geom_point(data = df.results.minor,aes(x = DD,y = CAGR),colour = "gray") +
geom_point(data = pareto.minor,aes(x = DD,y = CAGR),colour = "orange") +
plot = ggplot() +
geom_point(data = df.results.minor,aes(x = DD,y = CAGR),colour = "gray") +
geom_point(data = pareto.minor,aes(x = DD,y = CAGR),colour = "orange")
plot
melted.pareto.minor = melt(pareto.minor,id = c("CAGR","DD","SD"))
plot.stacked = ggplot(data = melted.pareto.minor,
aes(x = CAGR,y = value,fill = variable)) + geom_bar(stat = "identity")
plot.stacked
plot.stacked = ggplot(data = melted.pareto.minor,
aes(x = CAGR,y = value,fill = variable)) + geom_bar(stat = "identity")
melted.pareto.minor = melt(pareto.minor,id = c("CAGR","DD","SD"))
library(reshape2)
melted.pareto.minor = melt(pareto.minor,id = c("CAGR","DD","SD"))
plot.stacked = ggplot(data = melted.pareto.minor,
aes(x = CAGR,y = value,fill = variable)) + geom_bar(stat = "identity")
melted.pareto.minor = melt(pareto.minor,id = c("CAGR","DD","SD"))
melted.pareto.minor = melt(pareto.minor,id = c("CAGR","DD"))
plot.stacked = ggplot(data = melted.pareto.minor,
aes(x = CAGR,y = value,fill = variable)) + geom_bar(stat = "identity")
plot.stacked
max(df.results.minor$CAGR)
min(df.results.minor$CAGR)
plot.stacked = ggplot(data = melted.pareto.minor,
aes(x = CAGR,y = value,fill = variable)) +
geom_bar(stat = "identity") +
scale_x_continuous(limits = c(min(df.results.minor$CAGR),  max(df.results.minor$CAGR)))
plot.stacked
melted.pareto.minor
plot
df.results.minor
pareto.minor
a = seq(from = 0, to = 1,by = .05)
b = expand.grid(a,a,a,a)
c = b[rowSums(b) == 1,]
c
nrow(c)
source('D:/Dropbox/Github/retirement-planner/Harry Browne/harry_browne_shortterm.R')
plot
plot.stacked
df.pareto.minor
pareto.minor
plot
plot.stacked
plot
plot.stacked
plot.stacked
plot
plot.stacked
plot = ggplot() +
geom_point(data = df.results.minor,aes(x = CAGR,y = DD),colour = "gray") +
geom_point(data = pareto.minor,aes(x = CAGR,y = DD),colour = "orange")
plot
plot = ggplot() +
geom_point(data = df.results.minor,aes(x = CAGR,y = DD),colour = "gray") +
geom_point(data = pareto.minor,aes(x = CAGR,y = DD),colour = "orange")
plot.stacked
library(gridExtra)
grid.arrange(plot,plot.stacked,ncol = 1)
nrow(melted.pareto.minor)
nrow(pareto.minor)
plot.stacked
melted.pareto.minor
plot.stacked
plot.stacked = ggplot(data = melted.pareto.minor,
aes(x = CAGR,y = value,fill = variable)) +
geom_bar(stat = "identity",width=.5) +
scale_x_continuous(limits = c(min(df.results.minor$CAGR),  max(df.results.minor$CAGR)))
plot.stacked
plot.stacked = ggplot(data = melted.pareto.minor,
aes(x = CAGR,y = value,fill = variable)) +
geom_bar(stat = "identity",width=.01) +
scale_x_continuous(limits = c(min(df.results.minor$CAGR),  max(df.results.minor$CAGR)))
plot.stacked
plot.stacked = ggplot(data = melted.pareto.minor,
aes(x = CAGR,y = value,fill = variable)) +
geom_bar(stat = "identity",width=.001) +
scale_x_continuous(limits = c(min(df.results.minor$CAGR),  max(df.results.minor$CAGR)))
plot.stacked
plot.stacked = ggplot(data = melted.pareto.minor,
aes(x = CAGR,y = value,fill = variable)) +
geom_bar(stat = "identity",width=.01) +
scale_x_continuous(limits = c(min(df.results.minor$CAGR),  max(df.results.minor$CAGR)))
plot.stacked
grid.arrange(plot,plot.stacked,ncol = 1)
plot.stacked = ggplot(data = melted.pareto.minor,
aes(x = CAGR,y = value,fill = variable)) +
geom_bar(stat = "identity",width=.01) +
scale_x_continuous(limits = c(min(df.results.minor$CAGR),  max(df.results.minor$CAGR))) +
theme(legend.position="bottom")
plot.stacked
grid.arrange(plot,plot.stacked,ncol = 1)
plot.stacked = ggplot(data = melted.pareto.minor,
aes(x = CAGR,y = value,fill = variable)) +
geom_bar(stat = "identity",width=.0001) +
scale_x_continuous(limits = c(min(df.results.minor$CAGR),  max(df.results.minor$CAGR))) +
theme(legend.position="bottom")
plot.stacked
grid.arrange(plot,plot.stacked,ncol = 1)
plot.stacked = ggplot(data = melted.pareto.minor,
aes(x = CAGR,y = value,fill = variable)) +
geom_bar(stat = "identity",width=.005) +
scale_x_continuous(limits = c(min(df.results.minor$CAGR),  max(df.results.minor$CAGR))) +
theme(legend.position="bottom")
grid.arrange(plot,plot.stacked,ncol = 1)
c
save(data = df.results.minor,file = "df.harrybrowne.rda")
save(data = df.results.minor,file = "df.10_harrybrowne_spectrum.rda")
pareto.minor
load("df.10_harrybrowne_spectrum.rda")
pareto.minor = psel(df.results.minor, high(CAGR) * low(DD))
melted.pareto.minor = melt(pareto.minor,id = c("CAGR","DD"))
plot = ggplot() +
geom_point(data = df.results.minor,aes(x = CAGR,y = DD),colour = "gray") +
geom_point(data = pareto.minor,aes(x = CAGR,y = DD),colour = "orange")
plot.stacked = ggplot(data = melted.pareto.minor,
aes(x = CAGR,y = value,fill = variable)) +
geom_bar(stat = "identity",width=.005) +
scale_x_continuous(limits = c(min(df.results.minor$CAGR),  max(df.results.minor$CAGR))) +
theme(legend.position="bottom")
plot
plot.stacked
grid.arrange(plot,plot.stacked,ncol = 1)
library(ggplot2)  # for ggplot
library(rPref)    # for psel
library(reshape2) # for melt
library(gridExtra)
load("df.10_harrybrowne_spectrum.rda")
pareto.minor = psel(df.results.minor, high(CAGR) * low(DD))
melted.pareto.minor = melt(pareto.minor,id = c("CAGR","DD"))
plot = ggplot() +
geom_point(data = df.results.minor,aes(x = CAGR,y = DD),colour = "gray") +
geom_point(data = pareto.minor,aes(x = CAGR,y = DD),colour = "orange")
plot.stacked = ggplot(data = melted.pareto.minor,
aes(x = CAGR,y = value,fill = variable)) +
geom_bar(stat = "identity",width=.005) +
scale_x_continuous(limits = c(min(df.results.minor$CAGR),  max(df.results.minor$CAGR))) +
theme(legend.position="bottom")
grid.arrange(plot,plot.stacked,ncol = 1)
df.results.minor
save(data = df.results.minor,file = "df.10_harrybrowne_spectrum.rda")
getwd()
setwd("D:/Github/retirement-planner/Harry Browne")
getwd()
df.old.log
rm(list=ls())
library(readxl)
library(quantmod)
directory = "D:/Github/DataDrivenTrading/"
data_path = "D:/Github/DataDrivenTrading/Data/OHLC/"
setwd(directory)
# Load list of instruments
df <- data.frame(read_excel("etfdb_data.xls"))
colnames(df) = c("symbol","name","etfdb.category","inception.date","expense.ratio","commission.free","expenses.rating")
# Check file checker to determine which instruments need to be updated
existing.files = list.files("./Data/OHLC",full.names = FALSE) # fetch list of all files from folder
existing.files = gsub(".csv","",symbol.lihttps://www.google.com/webhp?hl=en&sa=X&ved=0ahUKEwjnrajXrL3PAhVEmZQKHYE4DVUQPAgDst) # remove ".csv" from vector of characters
# The update list determines if the file needs to be updated
df.updatelist = data.frame(stringsAsFactors=FALSE)
df.old.log = read.csv("log.csv")
df.old.log
write.csv(df.log,file = "log.csv",row.names=FALSE)
df.log = data.frame("fetched.symbol" = character(),
"fetch.attempted" = as.Date(character()),
"fetched.status" = character(),
stringsAsFactors=FALSE)
df.log
df.updatelist
existing.files
existing.files = gsub(".csv","",existing.files) # remove ".csv" from vector of characters
existing.files
