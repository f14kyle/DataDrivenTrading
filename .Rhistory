y = "Annualized Returns") +
facet_grid(. ~ Period) +
theme(legend.title=element_blank(),legend.position = "bottom")
plot.dd
scat.cagr.vs.md
plot.rebal1 = ggplot() +
geom_point(data = subset(df.lazy,Timeframe == "1 year"),aes(x = as.character(Name),y = as.numeric(CAGR),colour = Rebalance.Period),size = 2) +
scale_y_continuous(labels = percent) +
labs(title = "Sensitivity of CAGR to Rebalance Period for 1 Year Timeframe",
x = "Lazy Portfolios",
y = "Annualized Returns") +
theme(legend.title=element_blank(),
legend.position = "top",
axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.3))
plot.rebal3 = ggplot() +
geom_point(data = subset(df.lazy,Timeframe == "3 years"),aes(x = as.character(Name),y = as.numeric(CAGR),colour = Rebalance.Period),size = 2) +
scale_y_continuous(labels = percent) +
labs(title = "Sensitivity of CAGR to Rebalance Period for 3 Year Timeframe",
x = "Lazy Portfolios",
y = "Annualized Returns") +
theme(legend.title=element_blank(),
legend.position = "top",
axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.3))
plot.rebal5 = ggplot() +
geom_point(data = subset(df.lazy,Timeframe == "5 years"),aes(x = as.character(Name),y = as.numeric(CAGR),colour = Rebalance.Period),size = 2) +
scale_y_continuous(labels = percent) +
labs(title = "Sensitivity of CAGR to Rebalance Period for 5 Year Timeframe",
x = "Lazy Portfolios",
y = "Annualized Returns") +
theme(legend.title=element_blank(),
legend.position = "top",
axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.3))
plot.rebal7 = ggplot() +
geom_point(data = subset(df.lazy,Timeframe == "7 years"),aes(x = as.character(Name),y = as.numeric(CAGR),colour = Rebalance.Period),size = 2) +
scale_y_continuous(labels = percent) +
labs(title = "Sensitivity of CAGR to Rebalance Period for 7 Year Timeframe",
x = "Lazy Portfolios",
y = "Annualized Returns") +
theme(legend.title=element_blank(),
legend.position = "top",
axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.3))
scat.cagr.vs.dd = ggplot() +
geom_point(data = df.lazy,aes(x = as.numeric(levels(DD))[DD],y = as.numeric(CAGR),colour = Name)) +
scale_colour_manual(values = palette(rainbow(18))) +
theme_dark() +
scale_y_continuous(labels = percent) +
scale_x_continuous(labels = percent) +
labs(title = "Annualized Returns vs. Downside Deviation",
x = "Downside Deviation",
y = "Annualized Returns") +
facet_grid(Timeframe ~ Rebalance.Period,scales = "free") +
theme(legend.title=element_blank(),legend.position = "bottom")
scat.cagr.vs.md = ggplot() +
geom_point(data = df.lazy,aes(x = as.numeric(levels(MD))[MD],y = as.numeric(CAGR),colour = Name),size = 2) +
scale_colour_brewer(palette = "Spectral") +
theme_dark() +
scale_y_continuous(labels = percent) +
scale_x_continuous(labels = percent,trans = "reverse") +
labs(title = "Annualized Returns vs. Maximum Drawdown",
x = "Maximum Drawdown",
y = "Annualized Returns") +
facet_grid(Timeframe ~ Rebalance.Period) +
theme(legend.title=element_blank(),legend.position = "bottom")
scat.cagr.vs.md
scat.cagr.vs.dd
df.lazy
scat.cagr.vs.dd = ggplot() +
geom_point(data = df.lazy,aes(x = as.numeric(levels(DD))[DD],y = as.numeric(CAGR),colour = Name)) +
scale_colour_manual(values = palette(rainbow(18))) +
theme_dark() +
scale_y_continuous(labels = percent) +
scale_x_continuous(labels = percent) +
labs(title = "Annualized Returns vs. Downside Deviation",
x = "Downside Deviation",
y = "Annualized Returns") +
facet_grid(Timeframe ~ Rebalance.Period,scales = "free") +
theme(legend.title=element_blank(),legend.position = "bottom")
scat.cagr.vs.dd
scat.cagr.vs.md
source('D:/Dropbox/Github/retirement-planner/401k_analysis.R')
plot
source('D:/Dropbox/Github/boeing_401k/analysis.R')
# Overlay the market
# Overlay the funds
# Overlay the minimum constraints on funds
# Overlay the optimization
# Overlay Lifecycle 2050
# Overlay Balanced Index
library(quantmod)
library(PerformanceAnalytics)
library(ggplot2)
library(rPref)
tickers.bench = c("VTI","TLT","BIL","GOLD")
names.bench = c("Total Stocks","20+ Year Treasury","1-3 Month T-Bill","Swiss Gold")
tickers.count = length(tickers.bench)
for (i in 1:tickers.count){
try(getSymbols(tickers.bench[i], src = "yahoo"))
}
tickersZoo = "merge("
for (i in 1:tickers.count){
tickersZoo = paste(tickersZoo,tickers.bench[i],"[,6],",sep = "")
}
tickersZoo = paste(tickersZoo,")",sep = "")
tickersZoo = substr(tickersZoo,1,nchar(tickersZoo)-2)
tickersZoo = paste(tickersZoo,")",sep = "")
#allStocks = merge(GSPC[,6],RUT[,6],MSCI[,6],AGG[,6])
allStocks = merge(VTI[,6],TLT[,6],BIL[,6],GOLD[,6])
x.R =  na.omit(Return.calculate(allStocks["2006-01/2016-08"]))
a = seq(from = 0.1, to = 1,by = .05)
b = expand.grid(a,a,a,a)
c = b[rowSums(b) == 1,]
returns = as.xts(matrix(0,nrow = nrow(x.R), ncol = 4),order.by = index(x.R))
metrics.minor = matrix(0,nrow = nrow(c),ncol = 2)
for (i in 1:nrow(c)){
returns = Return.portfolio(x.R,weights = as.numeric(c[i,]),geometric = TRUE,rebalance_on = "years")
metrics.minor[i,1] = Return.annualized(returns, scale = NA, geometric = TRUE)
metrics.minor[i,2] = DownsideDeviation(returns, MAR = 0,method = "subset")
}
metrics.minor
df.results.minor = cbind(c,metrics.minor)
colnames(df.results.minor) = c("VTI","TLT","BIL","GOLD","CAGR","DD")
c
nrow(c)
metrics.minor
df.results.minor
head(df.results.minor)
pareto.minor = psel(df.results.minor, high(CAGR) * low(DD))
pareto.minor
plot = ggplot() +
geom_point(data = df.results.minor,aes(x = DD,y = CAGR),colour = "gray") +
geom_point(data = pareto.minor,aes(x = DD,y = CAGR),colour = "orange") +
plot = ggplot() +
geom_point(data = df.results.minor,aes(x = DD,y = CAGR),colour = "gray") +
geom_point(data = pareto.minor,aes(x = DD,y = CAGR),colour = "orange")
plot
melted.pareto.minor = melt(pareto.minor,id = c("CAGR","DD","SD"))
plot.stacked = ggplot(data = melted.pareto.minor,
aes(x = CAGR,y = value,fill = variable)) + geom_bar(stat = "identity")
plot.stacked
plot.stacked = ggplot(data = melted.pareto.minor,
aes(x = CAGR,y = value,fill = variable)) + geom_bar(stat = "identity")
melted.pareto.minor = melt(pareto.minor,id = c("CAGR","DD","SD"))
library(reshape2)
melted.pareto.minor = melt(pareto.minor,id = c("CAGR","DD","SD"))
plot.stacked = ggplot(data = melted.pareto.minor,
aes(x = CAGR,y = value,fill = variable)) + geom_bar(stat = "identity")
melted.pareto.minor = melt(pareto.minor,id = c("CAGR","DD","SD"))
melted.pareto.minor = melt(pareto.minor,id = c("CAGR","DD"))
plot.stacked = ggplot(data = melted.pareto.minor,
aes(x = CAGR,y = value,fill = variable)) + geom_bar(stat = "identity")
plot.stacked
max(df.results.minor$CAGR)
min(df.results.minor$CAGR)
plot.stacked = ggplot(data = melted.pareto.minor,
aes(x = CAGR,y = value,fill = variable)) +
geom_bar(stat = "identity") +
scale_x_continuous(limits = c(min(df.results.minor$CAGR),  max(df.results.minor$CAGR)))
plot.stacked
melted.pareto.minor
plot
df.results.minor
pareto.minor
a = seq(from = 0, to = 1,by = .05)
b = expand.grid(a,a,a,a)
c = b[rowSums(b) == 1,]
c
nrow(c)
source('D:/Dropbox/Github/retirement-planner/Harry Browne/harry_browne_shortterm.R')
plot
plot.stacked
df.pareto.minor
pareto.minor
plot
plot.stacked
plot
plot.stacked
plot.stacked
plot
plot.stacked
plot = ggplot() +
geom_point(data = df.results.minor,aes(x = CAGR,y = DD),colour = "gray") +
geom_point(data = pareto.minor,aes(x = CAGR,y = DD),colour = "orange")
plot
plot = ggplot() +
geom_point(data = df.results.minor,aes(x = CAGR,y = DD),colour = "gray") +
geom_point(data = pareto.minor,aes(x = CAGR,y = DD),colour = "orange")
plot.stacked
library(gridExtra)
grid.arrange(plot,plot.stacked,ncol = 1)
nrow(melted.pareto.minor)
nrow(pareto.minor)
plot.stacked
melted.pareto.minor
plot.stacked
plot.stacked = ggplot(data = melted.pareto.minor,
aes(x = CAGR,y = value,fill = variable)) +
geom_bar(stat = "identity",width=.5) +
scale_x_continuous(limits = c(min(df.results.minor$CAGR),  max(df.results.minor$CAGR)))
plot.stacked
plot.stacked = ggplot(data = melted.pareto.minor,
aes(x = CAGR,y = value,fill = variable)) +
geom_bar(stat = "identity",width=.01) +
scale_x_continuous(limits = c(min(df.results.minor$CAGR),  max(df.results.minor$CAGR)))
plot.stacked
plot.stacked = ggplot(data = melted.pareto.minor,
aes(x = CAGR,y = value,fill = variable)) +
geom_bar(stat = "identity",width=.001) +
scale_x_continuous(limits = c(min(df.results.minor$CAGR),  max(df.results.minor$CAGR)))
plot.stacked
plot.stacked = ggplot(data = melted.pareto.minor,
aes(x = CAGR,y = value,fill = variable)) +
geom_bar(stat = "identity",width=.01) +
scale_x_continuous(limits = c(min(df.results.minor$CAGR),  max(df.results.minor$CAGR)))
plot.stacked
grid.arrange(plot,plot.stacked,ncol = 1)
plot.stacked = ggplot(data = melted.pareto.minor,
aes(x = CAGR,y = value,fill = variable)) +
geom_bar(stat = "identity",width=.01) +
scale_x_continuous(limits = c(min(df.results.minor$CAGR),  max(df.results.minor$CAGR))) +
theme(legend.position="bottom")
plot.stacked
grid.arrange(plot,plot.stacked,ncol = 1)
plot.stacked = ggplot(data = melted.pareto.minor,
aes(x = CAGR,y = value,fill = variable)) +
geom_bar(stat = "identity",width=.0001) +
scale_x_continuous(limits = c(min(df.results.minor$CAGR),  max(df.results.minor$CAGR))) +
theme(legend.position="bottom")
plot.stacked
grid.arrange(plot,plot.stacked,ncol = 1)
plot.stacked = ggplot(data = melted.pareto.minor,
aes(x = CAGR,y = value,fill = variable)) +
geom_bar(stat = "identity",width=.005) +
scale_x_continuous(limits = c(min(df.results.minor$CAGR),  max(df.results.minor$CAGR))) +
theme(legend.position="bottom")
grid.arrange(plot,plot.stacked,ncol = 1)
c
save(data = df.results.minor,file = "df.harrybrowne.rda")
save(data = df.results.minor,file = "df.10_harrybrowne_spectrum.rda")
pareto.minor
load("df.10_harrybrowne_spectrum.rda")
pareto.minor = psel(df.results.minor, high(CAGR) * low(DD))
melted.pareto.minor = melt(pareto.minor,id = c("CAGR","DD"))
plot = ggplot() +
geom_point(data = df.results.minor,aes(x = CAGR,y = DD),colour = "gray") +
geom_point(data = pareto.minor,aes(x = CAGR,y = DD),colour = "orange")
plot.stacked = ggplot(data = melted.pareto.minor,
aes(x = CAGR,y = value,fill = variable)) +
geom_bar(stat = "identity",width=.005) +
scale_x_continuous(limits = c(min(df.results.minor$CAGR),  max(df.results.minor$CAGR))) +
theme(legend.position="bottom")
plot
plot.stacked
grid.arrange(plot,plot.stacked,ncol = 1)
library(ggplot2)  # for ggplot
library(rPref)    # for psel
library(reshape2) # for melt
library(gridExtra)
load("df.10_harrybrowne_spectrum.rda")
pareto.minor = psel(df.results.minor, high(CAGR) * low(DD))
melted.pareto.minor = melt(pareto.minor,id = c("CAGR","DD"))
plot = ggplot() +
geom_point(data = df.results.minor,aes(x = CAGR,y = DD),colour = "gray") +
geom_point(data = pareto.minor,aes(x = CAGR,y = DD),colour = "orange")
plot.stacked = ggplot(data = melted.pareto.minor,
aes(x = CAGR,y = value,fill = variable)) +
geom_bar(stat = "identity",width=.005) +
scale_x_continuous(limits = c(min(df.results.minor$CAGR),  max(df.results.minor$CAGR))) +
theme(legend.position="bottom")
grid.arrange(plot,plot.stacked,ncol = 1)
df.results.minor
save(data = df.results.minor,file = "df.10_harrybrowne_spectrum.rda")
getwd()
setwd("D:/Github/retirement-planner/Harry Browne")
getwd()
?read.xls
library(readxl)
df <- read_excel("ETFdb.xls")
rm(list=ls())
directory = "D:/Github/DataDrivenTrading"
setwd(directory)
df <- read_excel("ETFdb.xls")
df <- read_excel("etfdb_data.xls")
df
?read_excel
as.Date(df$Inception)
as.Date(df$Inception,origin = "1899-12-30")
head(df)
df$Commission freeny
df$Commission Free
# 9/24/2016
# ETF Metadata Scraper
# This program scrapes ETF metadata from ETFDB
rm(list=ls())
directory = "D:/Github/DataDrivenTrading"
setwd(directory)
# Load libraries
library(XML)
library(RCurl)
library(readxl)
# Load list of ETFs
# Source: http://www.nasdaq.com/etfs/list
# Only first two columns have relevant information
#df = read.csv(file="ETFList.csv", sep=",")[,1:2]
# Load list of ETFs
df <- read_excel("etfdb_data.xls",coltypes = c(""))
# Correct Excel format date for inception date
df$Inception = as.Date(df$Inception,origin = "1899-12-30")
# Create requisite columns
df["Issuer"] = gsub( " .*$", "", df$Name )
df["Structure"] = NA
df["Expense.Ratio"] = NA
df["Inception"] = NA
df["Tax.Form"] = NA
df["Tracking.Index"] = NA
df
df <- read_excel("etfdb_data.xls",coltypes = c(""))
# Correct Excel format date for inception date
df$Inception = as.Date(df$Inception,origin = "1899-12-30")
symbol	name	etfdb.category	inception.date	expense.ratio	commission.free	expenses.rating
df <- read_excel("etfdb_data.xls",coltypes = c(""))
colnames(df) = c("symbol","name","etfdb.category","inception.date","expense.ratio","commission.free","expenses.rating")
# Correct Excel format date for inception date
df$inception.date = as.Date(df$inception.date,origin = "1899-12-30")
df
head(df)
#df = read.csv(file="ETFList.csv", sep=",")[,1:2]
# Load list of ETFs
df <- read_excel("etfdb_data.xls"
colnames(df) = c("symbol","name","etfdb.category","inception.date","expense.ratio","commission.free","expenses.rating")
# Correct Excel format date for inception date
df$inception.date = as.Date(df$inception.date,origin = "1899-12-30")
df
df <- read_excel("etfdb_data.xls")
colnames(df) = c("symbol","name","etfdb.category","inception.date","expense.ratio","commission.free","expenses.rating")
# Correct Excel format date for inception date
df$inception.date = as.Date(df$inception.date,origin = "1899-12-30")
df
head(df)
df = data.frame(df)
# Create requisite columns
df["c.issuer"] = gsub( " .*$", "", df$name )
df["c.structure"] = NA
df["c.expense.ratio"] = NA
df["c.inception"] = NA
df["c.tax.form"] = NA
df["c.tracking.index"] = NA
head(df)
nrow(df)
nrow(df)/163
ceil(nrow(df)/163)
ceiling(nrow(df)/163)
?Sys.sleep
url.list <- paste("http://etfdb.com/etf/", df$symbol, sep="")
url.list
# Save all web content first
all.sites = vector("list",nrow(df))
# Determine how many loops to perform web crawling for
# ETFdb seems to cut the connection after 163 calls
n.loops = ceiling(nrow(df)/160)
for (i in 1:n.loops){
for (j in 160*i - 159:160 * i){
all.sites[[j]] = read_html(url.list[j])
}
Sys.sleep(2)
}
library(XML)
# Save all web content first
all.sites = vector("list",nrow(df))
# Determine how many loops to perform web crawling for
# ETFdb seems to cut the connection after 163 calls
n.loops = ceiling(nrow(df)/160)
for (i in 1:n.loops){
for (j in 160*i - 159:160 * i){
all.sites[[j]] = read_html(url.list[j])
}
Sys.sleep(2)
}
library(RCurl)
# Save all web content first
all.sites = vector("list",nrow(df))
# Determine how many loops to perform web crawling for
# ETFdb seems to cut the connection after 163 calls
n.loops = ceiling(nrow(df)/160)
for (i in 1:n.loops){
for (j in 160*i - 159:160 * i){
all.sites[[j]] = read_html(url.list[j])
}
Sys.sleep(2)
}
library(rvest) # for read_html
# Save all web content first
all.sites = vector("list",nrow(df))
# Determine how many loops to perform web crawling for
# ETFdb seems to cut the connection after 163 calls
n.loops = ceiling(nrow(df)/160)
for (i in 1:n.loops){
for (j in 160*i - 159:160 * i){
all.sites[[j]] = read_html(url.list[j])
}
Sys.sleep(2)
}
n.loops
all.sites
for (i in 1:n.loops){
for (j in 160*i - 159:160 * i){
all.sites[[j]] = read_html(url.list[j])
}
Sys.sleep(2)
}
for (i in 1:n.loops){
for (j in (160*i - 159):(160 * i)){
all.sites[[j]] = read_html(url.list[j])
}
Sys.sleep(2)
}
all.sites[[3]]
all.sites[[100]]
all.sites[[300]]
all.sites[[170]]
all.sites[[200]]
all.sites[[300]]
all.sites[[250]]
all.sites[[270]]
all.sites[[250]]
all.sites[[253]]
all.sites[[255]]
all.sites[[260]]
all.sites[[265]]
all.sites[[269]]
all.sites[[170]]
all.sites[[175]]
all.sites[[180]]
all.sites[[250]]
all.sites[[270]]
all.sites[[260]]
all.sites[[265]]
all.sites[[267]]
all.sites[[268]]
all.sites[[269]]
all.sites[[270]]
all.sites[[269]]
for (j in 270: 356){
all.sites[[j]] = read_html(url.list[j])
}
all.sites[[269]]
for (j in 270: 356){
all.sites[[j]] = read_html(url.list[j])
}
all.sites[[270]] = read_html(url.list[270])
all.sites[[271]] = read_html(url.list[271])
for (j in 272: 356){
all.sites[[j]] = read_html(url.list[j])
}
Sys.sleep(2)
all.sites[280]
all.sites[279]
all.sites[280]
all.sites[281]
all.sites[300]
all.sites[299]
all.sites[297]
all.sites[296]
for (j in 297: 356){
all.sites[[j]] = read_html(url.list[j])
}
for (j in 298: 356){
all.sites[[j]] = read_html(url.list[j])
}
all.sites[[356]]
save(all.sites,file = "20160930_allsites.rda")
for (i in 1:nrow(df)){
cast <- html_nodes(all.sites[[i]], ".pull-right")
df$Issuer[i] = html_text(cast)[6]
df$Structure[i] = html_text(cast)[7]
df$Expense.Ratio[i] = html_text(cast)[8]
df$Inception[i] = html_text(cast)[10]
df$Tax.Form[i] = html_text(cast)[11]
df$Tracking.Index[i] = html_text(cast)[12]
}
df
head(df)
View(df)
nrow(df)
rm(df)
df <- data.frame(read_excel("etfdb_data.xls"))
colnames(df) = c("symbol","name","etfdb.category","inception.date","expense.ratio","commission.free","expenses.rating")
# Correct Excel format date for inception date
df$inception.date = as.Date(df$inception.date,origin = "1899-12-30")
# Create requisite columns
df["c.issuer"] = gsub( " .*$", "", df$name )
df["c.structure"] = NA
df["c.expense.ratio"] = NA
df["c.inception"] = NA
df["c.tax.form"] = NA
df["c.tracking.index"] = NA
?try
for (i in 1:nrow(df)){
cast <- try(html_nodes(all.sites[[i]], ".pull-right"))
df$c.issuer[i] = try(html_text(cast)[6])
df$c.structure[i] = try(html_text(cast)[7])
df$c.expense.ratio[i] = try(html_text(cast)[8])
df$c.inception.date[i] = try(html_text(cast)[10])
df$c.tax.form[i] = try(html_text(cast)[11])
df$c.tracking.index[i] = try(html_text(cast)[12])
}
i
View(df)
html_text(cast)[7]
html_text(cast)[6]
html_text(cast)[8]
html_text(cast)[9]
df
